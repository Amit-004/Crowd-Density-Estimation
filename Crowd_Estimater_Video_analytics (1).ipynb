{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2834811c-c629-450f-86ba-77260549712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Number: 1\n",
      "Number of People Detected: 57\n",
      "Frame Number: 2\n",
      "Number of People Detected: 56\n",
      "Frame Number: 3\n",
      "Number of People Detected: 54\n",
      "Frame Number: 4\n",
      "Number of People Detected: 49\n",
      "Frame Number: 5\n",
      "Number of People Detected: 49\n",
      "Frame Number: 6\n",
      "Number of People Detected: 54\n",
      "Frame Number: 7\n",
      "Number of People Detected: 62\n",
      "Frame Number: 8\n",
      "Number of People Detected: 57\n",
      "Frame Number: 9\n",
      "Number of People Detected: 57\n",
      "Frame Number: 10\n",
      "Number of People Detected: 55\n",
      "Frame Number: 11\n",
      "Number of People Detected: 51\n",
      "Frame Number: 12\n",
      "Number of People Detected: 55\n",
      "Frame Number: 13\n",
      "Number of People Detected: 53\n",
      "Frame Number: 14\n",
      "Number of People Detected: 52\n",
      "Frame Number: 15\n",
      "Number of People Detected: 52\n",
      "Frame Number: 16\n",
      "Number of People Detected: 49\n",
      "Frame Number: 17\n",
      "Number of People Detected: 45\n",
      "Frame Number: 18\n",
      "Number of People Detected: 46\n",
      "Frame Number: 19\n",
      "Number of People Detected: 43\n",
      "Frame Number: 20\n",
      "Number of People Detected: 48\n",
      "Frame Number: 21\n",
      "Number of People Detected: 52\n",
      "Frame Number: 22\n",
      "Number of People Detected: 42\n",
      "Frame Number: 23\n",
      "Number of People Detected: 45\n",
      "Frame Number: 24\n",
      "Number of People Detected: 53\n",
      "Frame Number: 25\n",
      "Number of People Detected: 48\n",
      "Frame Number: 26\n",
      "Number of People Detected: 51\n",
      "Frame Number: 27\n",
      "Number of People Detected: 54\n",
      "Frame Number: 28\n",
      "Number of People Detected: 48\n",
      "Frame Number: 29\n",
      "Number of People Detected: 49\n",
      "Frame Number: 30\n",
      "Number of People Detected: 47\n",
      "Frame Number: 31\n",
      "Number of People Detected: 46\n",
      "Frame Number: 32\n",
      "Number of People Detected: 46\n",
      "Frame Number: 33\n",
      "Number of People Detected: 46\n",
      "Frame Number: 34\n",
      "Number of People Detected: 46\n",
      "Frame Number: 35\n",
      "Number of People Detected: 49\n",
      "Frame Number: 36\n",
      "Number of People Detected: 51\n",
      "Frame Number: 37\n",
      "Number of People Detected: 51\n",
      "Frame Number: 38\n",
      "Number of People Detected: 50\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "# Define constants and paths\n",
    "MIN_CONF = 0.3\n",
    "NMS_THRESH = 0.3\n",
    "MIN_DISTANCE = 50\n",
    "MODEL_PATH = \"D:\\\\Video_analytic_assignment\\\\Project\\\\coco.names\"\n",
    "weightsPath = \"D:\\\\Video_analytic_assignment\\\\Project\\\\yolov3.weights\"\n",
    "configPath = \"D:\\\\Video_analytic_assignment\\\\Project\\\\yolov3.cfg\"\n",
    "\n",
    "# Load the YOLO model\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "labels = open(MODEL_PATH).read().strip().split(\"\\n\")\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Define function to detect people\n",
    "def detect_people(frame, net, ln, personIdx=0):\n",
    "    # grab the dimensions of the frame\n",
    "    (H, W) = frame.shape[:2]\n",
    "\n",
    "    # initialize the list of results\n",
    "    results = []\n",
    "\n",
    "    # construct a blob from the input frame and then perform a forward\n",
    "    # pass of the YOLO object detector, giving us our bounding boxes\n",
    "    # and associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (832, 832), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "\n",
    "    # initialize our lists of detected bounding boxes, centroids, and\n",
    "    # confidences, respectively\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence (i.e., probability)\n",
    "            # of the current object detection\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # filter detections by (1) ensuring that the object\n",
    "            # detected was a person and (2) that the minimum\n",
    "            # confidence is met\n",
    "            if classID == personIdx and confidence > MIN_CONF:\n",
    "                # scale the bounding box coordinates back relative to\n",
    "                # the size of the image, keeping in mind that YOLO\n",
    "                # actually returns the center (x, y)-coordinates of\n",
    "                # the bounding box followed by the boxes' width and\n",
    "                # height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top\n",
    "                # and and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # update our list of bounding box coordinates,\n",
    "                # centroids, and confidences\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                centroids.append((centerX, centerY))\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    # bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONF, NMS_THRESH)\n",
    "\n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            # update our results list to consist of the person\n",
    "            # prediction probability, bounding box coordinates,\n",
    "            # and the centroid\n",
    "            r = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "            results.append(r)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to generate density map\n",
    "def generate_density_map(frame, results):\n",
    "    density_map = np.zeros(frame.shape[:2], dtype=np.float32)\n",
    "\n",
    "    # Generate density map based on detected people\n",
    "    for (_, _, centroid) in results:\n",
    "        (cX, cY) = centroid\n",
    "        density_map[cY, cX] += 1\n",
    "\n",
    "    # Apply Gaussian blur to smooth density map\n",
    "    density_map = cv2.GaussianBlur(density_map, (21, 21), 0)\n",
    "\n",
    "    # Normalize density map\n",
    "    density_map = cv2.normalize(density_map, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    density_map = np.uint8(density_map)\n",
    "\n",
    "    return density_map\n",
    "\n",
    "# Function to estimate number of people based on density\n",
    "def estimate_people_count(density_map, threshold):\n",
    "    # Threshold the density map to count the number of people\n",
    "    _, binary_map = cv2.threshold(density_map, threshold, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    people_count = len(contours)\n",
    "\n",
    "    return people_count\n",
    "\n",
    "# Function to overlay heatmap on frame\n",
    "def overlay_heatmap(frame, density_map):\n",
    "    # Convert density map to RGB format\n",
    "    heatmap = cv2.applyColorMap(density_map, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Overlay heatmap on frame\n",
    "    frame_with_heatmap = cv2.addWeighted(frame, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    return frame_with_heatmap\n",
    "\n",
    "# Initialize video capture\n",
    "vs = cv2.VideoCapture(\"D:\\\\Video_analytic_assignment\\\\Project\\\\new_1.mp4\")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"D:\\\\Video_analytic_assignment\\\\Crowd_counter_project\\\\output_path\\\\video_data.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create a table to store the frame number and people count\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS video_data\n",
    "               (frame_number INTEGER PRIMARY KEY, people_count INTEGER)''')\n",
    "\n",
    "# Loop over video frames\n",
    "frame_number = 0\n",
    "while True:\n",
    "    # Read the next frame\n",
    "    (grabbed, frame) = vs.read()\n",
    "    frame_number += 1\n",
    "\n",
    "    # If the frame was not grabbed, exit loop\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # Resize the frame and detect people in it\n",
    "    frame = imutils.resize(frame, width=700)\n",
    "    results = detect_people(frame, net, ln, personIdx=labels.index(\"person\"))\n",
    "\n",
    "    # Print the length of results and frame number for debugging\n",
    "    print(\"Frame Number:\", frame_number)\n",
    "    print(\"Number of People Detected:\", len(results))\n",
    "\n",
    "    # Check if results is None\n",
    "    if results is None:\n",
    "        print(\"No people detected in the frame.\")\n",
    "        continue\n",
    "\n",
    "    # Generate density map based on detected people\n",
    "    density_map = generate_density_map(frame, results)\n",
    "    # Estimate number of people based on density\n",
    "    threshold = 100  # Adjust this threshold value as needed\n",
    "    people_count = estimate_people_count(density_map, threshold)\n",
    "\n",
    "    # Overlay heatmap on frame\n",
    "    frame_with_heatmap = overlay_heatmap(frame, density_map)\n",
    "\n",
    "    # Display the frame with heatmap and people count\n",
    "    cv2.putText(frame_with_heatmap, f\"People Count: {people_count}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Frame with Heatmap and People estimate\", frame_with_heatmap)\n",
    "\n",
    "    # Store data in the SQLite database\n",
    "    # cur.execute(\"INSERT INTO video_data (frame_number, people_count) VALUES (?, ?)\", (frame_number, people_count))\n",
    "    conn.commit()\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If 'q' key pressed, break from loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release video capture and close windows\n",
    "vs.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Close the SQLite connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db35ed3-7b78-46be-b75b-236ef373989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 55)\n",
      "(2, 56)\n",
      "(3, 54)\n",
      "(4, 49)\n",
      "(5, 49)\n",
      "(6, 54)\n",
      "(7, 59)\n",
      "(8, 56)\n",
      "(9, 56)\n",
      "(10, 54)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"D:\\\\Video_analytic_assignment\\\\Crowd_counter_project\\\\output_path\\\\video_data.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a simple query to fetch all data from the table\n",
    "# cur.execute(\"SELECT * FROM video_data\")\n",
    "cur.execute(\"SELECT * FROM video_data LIMIT 10\")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Print the fetched data\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f04420-2993-4205-ab7d-4c88f38009fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
